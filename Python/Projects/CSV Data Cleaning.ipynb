{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Titles Data Cleaning Project\n",
    "\n",
    "## Overview\n",
    "This project demonstrates data cleaning techniques using a dataset of Netflix titles (`netflix_titles.csv`). The goal is to preprocess the data by handling missing values, splitting columns, and extracting meaningful features for further analysis. This portfolio project showcases proficiency in Python, Pandas, and data wrangling.\n",
    "\n",
    "## Objectives\n",
    "- Identify and quantify missing data.\n",
    "- Handle missing values appropriately.\n",
    "- Transform and extract features from text-based columns.\n",
    "- Prepare the dataset for downstream analysis or visualization.\n",
    "\n",
    "## Tools Used\n",
    "- **Python Libraries**: Pandas, NumPy, SciPy, Seaborn, Regular Expressions (re)\n",
    "- **Dataset**: `netflix_titles.csv` (sourced locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import babel as bl\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import re\n",
    "from scipy import stats\n",
    "from babel import numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset\n",
    "We begin by loading the Netflix titles dataset from a CSV file and inspecting the first row to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/brtelfer/Documents/Python_Data_Projects/*17_Data_Cleaning/netflix_titles.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Assess Missing Data\n",
    "To understand the quality of the dataset, we calculate the number of missing values in each column and sort them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Missing Data as Percentages\n",
    "Next, we compute the percentage of missing values for each column to better assess their impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_lst = [df.columns.to_list()]\n",
    "results = []\n",
    "for column in col_lst:\n",
    "    results.append(df[column].isnull().mean())\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [round(i * 100, 2) for i in results]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Handle Missing Directors\n",
    "The `director` column has a significant amount of missing data (approximately 31.58%). We explore options to handle this, such as dropping rows with missing directors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['director'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'director' is missing\n",
    "no_director = df[df['director'].isnull()].index\n",
    "df.drop(no_director, axis=0).isnull().sum()\n",
    "df[~(df['director'].isnull())]  # Alternative method\n",
    "df.dropna(subset=['director'])  # Preferred method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Impute Missing Ratings\n",
    "For columns with fewer missing values, like `rating`, we impute missing entries with the most frequent (mode) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({'rating': ''.join(df['rating'].mode())}).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split Duration Column\n",
    "The `duration` column contains both numeric values and units (e.g., '90 min' or '1 Season'). We split it into two columns: `duration num` (numeric) and `duration type` (unit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration num'] = df['duration'].str.split(' ').str[0]\n",
    "df['duration type'] = df['duration'].str.split(' ').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Numeric Duration for Movies\n",
    "For movies specifically, we extract the numeric portion of `duration` and convert it to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['type'] == 'Movie']['duration'].str.split().str[0].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Parse Date Added\n",
    "The `date_added` column (e.g., 'September 9, 2019') is split into separate `year`, `month`, and `day` columns using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date_added'].str.extract('(\\d{4})')\n",
    "df['month'] = df['date_added'].str.extract('(\\w+) ')\n",
    "df['day'] = df['date_added'].str.extract(' (\\d{2}|\\d),')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date_added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Date Parsing\n",
    "As an alternative approach, we test parsing dates into months using `pd.to_datetime` on a smaller sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'date_added': [\"September 9, 2018\", \"October 10, 2019\", \"November 11, 2020\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df['date_added'].str.extract('\\s(\\d{2}|\\d),')  # Extract day\n",
    "pd.to_datetime(df['date_added'].str.strip()).dt.month  # Extract month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This project successfully cleaned the Netflix titles dataset by:\n",
    "- Quantifying and addressing missing data.\n",
    "- Imputing missing ratings with the mode.\n",
    "- Splitting the `duration` column into numeric and type components.\n",
    "- Parsing the `date_added` column into year, month, and day.\n",
    "\n",
    "The cleaned dataset is now ready for exploratory data analysis, visualization, or modeling. Future steps could include analyzing trends in movie durations or release patterns over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote_Work_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
